{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of LR_using_Pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UK1pemhtrthU",
        "colab_type": "text"
      },
      "source": [
        "# **Linear Regression using Pytorch from scratch**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJYDQCLTr5wM",
        "colab_type": "text"
      },
      "source": [
        "We will start with Numpy and then look at Pytorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tftOH2Q4z_YM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-DYfiiaz_4W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Data Generation\n",
        "np.random.seed(42)\n",
        "x = np.random.rand(100, 1)\n",
        "\n",
        "# Below equation is y = a + bx + noise where a = 1 and b = 2\n",
        "y = 1 + 2 * x + .1 * np.random.randn(100, 1)\n",
        "\n",
        "# Shuffles the indices\n",
        "idx = np.arange(100)\n",
        "np.random.shuffle(idx)\n",
        "\n",
        "# Uses first 80 random indices for train\n",
        "train_idx = idx[:80]\n",
        "# Uses the remaining indices for validation\n",
        "val_idx = idx[80:]\n",
        "\n",
        "# Generates train and validation sets\n",
        "x_train, y_train = x[train_idx], y[train_idx]\n",
        "x_val, y_val = x[val_idx], y[val_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEKEgtkl3gOQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "b5f23d9d-0e22-4112-9cac-99209e6f3932"
      },
      "source": [
        "x_train[:5], y_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([[0.77127035],\n",
              "        [0.06355835],\n",
              "        [0.86310343],\n",
              "        [0.02541913],\n",
              "        [0.73199394]]), array([[2.47453822],\n",
              "        [1.19277206],\n",
              "        [2.9127843 ],\n",
              "        [1.07850733],\n",
              "        [2.47316396]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6fplfAD3xwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5e4859ee-20a2-4ef6-e33c-860ba5a42d83"
      },
      "source": [
        "print(type(x_train))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVSJqr6R0Fk7",
        "colab_type": "text"
      },
      "source": [
        "Above code cells are to create the data as Numpy arrays. This is the same data that we created in LR model with Numpy. \n",
        "https://github.com/manjunathrgithub/Simple-LR-Model-with-Numpy \n",
        "\n",
        "We will convert the numpy arrays into Tensors in below cells so that we can use them with Pytorch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjLqwtQw4Qn0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "outputId": "e4c07956-b793-41ac-cfa2-31b9855cb936"
      },
      "source": [
        "# Installing torchviz since it was not pre-installed on this GPU.\n",
        "!pip install torchviz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting torchviz\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/8e/a9630c7786b846d08b47714dd363a051f5e37b4ea0e534460d8cdfc1644b/torchviz-0.0.1.tar.gz (41kB)\n",
            "\r\u001b[K     |████████                        | 10kB 30.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 40kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 51kB 2.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.6/dist-packages (from torchviz) (1.3.1)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.6/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torch->torchviz) (1.17.4)\n",
            "Building wheels for collected packages: torchviz\n",
            "  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchviz: filename=torchviz-0.0.1-cp36-none-any.whl size=3520 sha256=28d2000b9a7b828cc19400716528eb1a55cf9aadeea8860bf65c75189b590f79\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/c2/c5/b8b4d0f7992c735f6db5bfa3c5f354cf36502037ca2b585667\n",
            "Successfully built torchviz\n",
            "Installing collected packages: torchviz\n",
            "Successfully installed torchviz-0.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qjV2_1jDdrr3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Library Imports\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchviz import make_dot\n",
        "\n",
        "#Setting the Device to CPU or GPU based on the availability\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H2Lc_XMP4FJP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "aa9c8601-0c6d-4338-c832-7d6b7495d106"
      },
      "source": [
        "print(device) #Since we are using GPU here, devide shows as cuda. Otherwise it would show as cpu."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jPPwHPzxzW09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# In https://github.com/manjunathrgithub/Simple-LR-Model-with-Numpy the data was in Numpy arrays. \n",
        "# For using with Pytorch, we need to have PyTorch's Tensors\n",
        "# \n",
        "x_train_tensor = torch.from_numpy(x_train).float().to(device)\n",
        "y_train_tensor = torch.from_numpy(y_train).float().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1udw2rDQzb_q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dfdca78b-4c81-4a98-c584-01fa8e1cf9ce"
      },
      "source": [
        "print(type(x_train), type(x_train_tensor), x_train_tensor.type())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.ndarray'> <class 'torch.Tensor'> torch.cuda.FloatTensor\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXwV4dFOzKw5",
        "colab_type": "text"
      },
      "source": [
        "We can see x_train_tensor is now a Tensor and .type() shows that it is a Tensor which is on GPU and is of Float datatype"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vDsrW5P-7hCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6e4ed59-d0c6-4bce-a42e-c163c4495f18"
      },
      "source": [
        "# Initializing a and b to random values\n",
        "# This is similar to what we did in Numpy.\n",
        "# We set REQUIRES_GRAD = TRUE because we want to calculate partial derivatives or gradients on these parameters\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float)\n",
        "print(a, b)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-0.0125], requires_grad=True) tensor([-0.2016], requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLol4Wkc8DyD",
        "colab_type": "text"
      },
      "source": [
        "This looks good. These are Tensors and can be used with Pytorch. Is it ??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBqQz3Yq8K_x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d505d3c-71a7-47c7-c93c-24aa1cb75cb0"
      },
      "source": [
        "a.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5HS1UBIO8O2U",
        "colab_type": "text"
      },
      "source": [
        "This is a Float Tensor but resides on CPU. To use GPU, we need to push it to GPU. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H_2FNspB8V_m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = a.to(device)\n",
        "b = b.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q6fjtg4n89WE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b78fd7f6-5a02-48a4-e531-70177f136d1b"
      },
      "source": [
        "a.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.cuda.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SLREG4P59C8m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fbc0e269-9507-4e56-c6ac-3ed3e3f8b3a8"
      },
      "source": [
        "b.type()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'torch.cuda.FloatTensor'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BLZWZko39KjY",
        "colab_type": "text"
      },
      "source": [
        "Okay. Now we have pushed them to GPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dov9pJCGHr5R",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "edc4e4e7-5c2b-4bbf-b2e6-b7b66926a3c8"
      },
      "source": [
        "a, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.0125], device='cuda:0', grad_fn=<CopyBackwards>),\n",
              " tensor([-0.2016], device='cuda:0', grad_fn=<CopyBackwards>))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mp9lvYynHw3U",
        "colab_type": "text"
      },
      "source": [
        "What happened to requires_grad=True !? Looks like we lost it when we moved to GPU. \n",
        "So, this is not the right approach to create Tensors on GPU which require gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JjxQ0r_F7pKx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We can create regular float tensors and send them to the device.\n",
        "a = torch.randn(1, dtype=torch.float).to(device)\n",
        "b = torch.randn(1, dtype=torch.float).to(device)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cb9GogzPJXmL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "347b42b3-dc88-4ad9-cea4-e24e1d5648e9"
      },
      "source": [
        "# and therafter set them as requiring gradients i.e. requires_grad = True\n",
        "a.requires_grad_()\n",
        "b.requires_grad_()\n",
        "a, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([-0.4192], device='cuda:0', requires_grad=True),\n",
              " tensor([-0.1465], device='cuda:0', requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OEnOUMyMJo5G",
        "colab_type": "text"
      },
      "source": [
        "# However the best way is to create the Tensors right away on GPU instead of all this moving around. \n",
        "# The output of this and above cells is essentially the same, but this is a best practice and straightforward. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu5Rjqm5JxJE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "19afc99f-7e01-485d-fd26-cae9c7ae4bbb"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "a, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.1940], device='cuda:0', requires_grad=True),\n",
              " tensor([0.1391], device='cuda:0', requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Len3hrsAKGr1",
        "colab_type": "text"
      },
      "source": [
        "Okay.. Now we have a and b Tensors on GPU.. \n",
        "What next ? Start Forward Pass -> calculate Loss -> calculate gradients -> do backward pass and repeat it for number of epochs ??"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAwnRCr9O-8X",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# set a learning rate and number of epochs\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwewiYIbWY_u",
        "colab_type": "text"
      },
      "source": [
        "In this next section we will run a for loop and calculate the predictions, error and MSE loss similar to what we did before in \n",
        "LR with Numpy exercise. \n",
        "\n",
        "However we will not calculate the gradient by hand. Rather we will use Pytorch's autograd function and its capabilities. \n",
        "Autograd is PyTorch’s automatic differentiation package and it will take care of calculating Partial Derivatives,\n",
        "Chain rule of derivatives where we multiply different partial derivatives to get a final derivative and so on.\n",
        "\n",
        "It will also keep accumulating the gradient for each change of that object. We have set a and b to requires_grad=True.\n",
        "Therefore gradients will be calculated for them by Pytorch. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bObpveYGVbdk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 405
        },
        "outputId": "dbd1c7d2-dfee-49ab-a1b1-8da595f408b9"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "    \n",
        "    # Lets print a and b before the backward pass.\n",
        "    print(\"epoch number =\", epoch)\n",
        "    print(\"a and b before backward pass\" , a,b)\n",
        "\n",
        "    # We will not do this now like we did in Numpy notebook \n",
        "    # - https://github.com/manjunathrgithub/Simple-LR-Model-with-Numpy/blob/master/LR_Using_Numpy.ipynb\n",
        "    # a_grad = -2 * error.mean()\n",
        "    # b_grad = -2 * (x_tensor * error).mean()\n",
        "    \n",
        "    # We will tell PyTorch to do the back progagation to the beginning from the specified loss which is at the end. \n",
        "    loss.backward()\n",
        "    # Let's check the computed gradients...\n",
        "    type(a.grad)\n",
        "    print(\"a's gradient = \" , a.grad) \n",
        "    print(\"b's gradient = \" , b.grad)\n",
        "    \n",
        "    # Let's try to update the parameters with the formula we know - parameters = parameters - learning rate* gradient(parameters wrto Loss function)\n",
        "  \n",
        "    a = a - lr * a.grad\n",
        "    b = b - lr * b.grad\n",
        "    print(\"a and b after backward pass\" , a,b)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number = 0\n",
            "a and b before backward pass tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-3.3881], device='cuda:0')\n",
            "b's gradient =  tensor([-1.9439], device='cuda:0')\n",
            "a and b after backward pass tensor([0.5328], device='cuda:0', grad_fn=<SubBackward0>) tensor([0.3335], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "epoch number = 1\n",
            "a and b before backward pass tensor([0.5328], device='cuda:0', grad_fn=<SubBackward0>) tensor([0.3335], device='cuda:0', grad_fn=<SubBackward0>)\n",
            "a's gradient =  None\n",
            "b's gradient =  None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-ee387fc7ae7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Let's try to update the parameters with the formula we know - parameters = parameters - learning rate* gradient(parameters wrto Loss function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mb\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a and b after backward pass\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XeuyT1BbS2l",
        "colab_type": "text"
      },
      "source": [
        "Well.. It did not work. a.grad and b.grad became None after epoch 0 and the parameter update statement fails for epoch 1. \n",
        "What happened ?\n",
        "\n",
        "epoch number = 0\n",
        "a and b before backward pass tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
        "\n",
        "See what happened after backward pass during epoch 0. The requires_grad=True vanished again after a and b were reassigned new values. \n",
        "This is similar to what happened before when we moved a and b from CPU to GPU. \n",
        "See here. Link to the cell - https://colab.research.google.com/drive/1OBbzaMpf33M8Fc-Z1yY0jqFKLScvYgco#scrollTo=mp9lvYynHw3U\n",
        "\n",
        "a and b after backward pass tensor([0.5328], device='cuda:0', grad_fn=<SubBackward0>) tensor([0.3335], device='cuda:0', grad_fn=<SubBackward0>)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3PCSR8kpfCGc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d952d8ac-0c30-4311-a020-97f59c8961b5"
      },
      "source": [
        "print(a, b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.5328], device='cuda:0', grad_fn=<SubBackward0>) tensor([0.3335], device='cuda:0', grad_fn=<SubBackward0>)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyRIEihCVvNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now a and b are messed up. So, I initialize them again. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lXHWbnV0e71U",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "da842b2e-a22b-4e44-b1a7-aec595c3059f"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "a, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.1940], device='cuda:0', requires_grad=True),\n",
              " tensor([0.1391], device='cuda:0', requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jSvVR_6lViKw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a218ef46-2a9f-4ac4-c739-a64488390797"
      },
      "source": [
        "print(a, b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R0P04f9qfFzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets try something else"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bz3k4C3AfI7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 320
        },
        "outputId": "39460307-acc9-4e19-d57d-bfbfc1468b38"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "    \n",
        "    # Lets print a and b before the backward pass.\n",
        "    print(\"epoch number =\", epoch)\n",
        "    print(\"a and b before backward pass\" , a,b)\n",
        "\n",
        "    # We will not do this now like we did in Numpy notebook \n",
        "    # - https://github.com/manjunathrgithub/Simple-LR-Model-with-Numpy/blob/master/LR_Using_Numpy.ipynb\n",
        "    # a_grad = -2 * error.mean()\n",
        "    # b_grad = -2 * (x_tensor * error).mean()\n",
        "    \n",
        "    # We will tell PyTorch to do the back progagation to the beginning from the specified loss which is at the end. \n",
        "    loss.backward()\n",
        "    # Let's check the computed gradients...\n",
        "    type(a.grad)\n",
        "    print(\"a's gradient = \" , a.grad) \n",
        "    print(\"b's gradient = \" , b.grad)\n",
        "    \n",
        "    # Let's try to update the parameters with the formula we know - parameters = parameters - learning rate* gradient(parameters wrto Loss function)\n",
        "  \n",
        "    a-= lr * a.grad\n",
        "    b.sub_(lr * b.grad)\n",
        "    print(\"a and b after backward pass\" , a,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number = 0\n",
            "a and b before backward pass tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-3.3881], device='cuda:0')\n",
            "b's gradient =  tensor([-1.9439], device='cuda:0')\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-51-83082fa8169f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Let's try to update the parameters with the formula we know - parameters = parameters - learning rate* gradient(parameters wrto Loss function)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0ma\u001b[0m\u001b[0;34m-=\u001b[0m \u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msub_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"a and b after backward pass\"\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: a leaf Variable that requires grad has been used in an in-place operation."
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8sg3dLudfcWU",
        "colab_type": "text"
      },
      "source": [
        "We used the inplace value substitution instead of assigning to a and b. There are two ways to do it and both are shown above i.e. a-= or b.sub_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKHgjHhgf4LU",
        "colab_type": "text"
      },
      "source": [
        " It does not even finish epoch 0. It fails when assigning the value. This is because of Pytorch's Dynamic Computational Graph\n",
        "Basically since required_grad is set to True for a and b, pytorch is calculating gradients and storing them for each change to a and b. \n",
        "\n",
        "Since we are trying to change the same object using its own value, it throws an error. \n",
        "We need to basically somehow tell Pytorch not to calculate gradient for a and b when we are doing this parameter update step. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiSCpUoUhZJT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now a and b are messed up again. So, I initialize them yet again. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "iP_eRECJhZJW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "9d98d86b-8bd2-4da8-cd29-767dea1730ec"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "a, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.1940], device='cuda:0', requires_grad=True),\n",
              " tensor([0.1391], device='cuda:0', requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "D-e8JL8IhZJa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8f00d5be-4124-4126-b50b-bc9f3600f36c"
      },
      "source": [
        "print(a, b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k1iYFyPyhZJc",
        "colab_type": "text"
      },
      "source": [
        "# Lets try something else now. We will tell Pytorch not to compute gradients when we are doing the parameter update. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UyhFkzwShRuL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 867
        },
        "outputId": "d4b706ea-723f-46c9-9113-0324d8be3a85"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "    \n",
        "    # Lets print a and b before the backward pass for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "      print(\"epoch number =\", epoch)\n",
        "      print(\"a and b before backward pass\" , a,b)\n",
        "\n",
        "    # We will not do this now like we did in Numpy notebook \n",
        "    # - https://github.com/manjunathrgithub/Simple-LR-Model-with-Numpy/blob/master/LR_Using_Numpy.ipynb\n",
        "    # a_grad = -2 * error.mean()\n",
        "    # b_grad = -2 * (x_tensor * error).mean()\n",
        "    \n",
        "    # We will tell PyTorch to do the back progagation to the beginning from the specified loss which is at the end. \n",
        "    loss.backward()\n",
        "    # Let's check the computed gradients...\n",
        "    # Lets print the gradients for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "      print(\"a's gradient = \" , a.grad) \n",
        "      print(\"b's gradient = \" , b.grad)\n",
        "    \n",
        "    # Let's try to update the parameters with the formula we know - parameters = parameters - learning rate* gradient(parameters wrto Loss function)\n",
        "    # We are telling Pytorch not to calculate gradients for steps within the \"with\"\n",
        "    # torch.no_grad() allows us to perform regular Python operations on tensors, independent of PyTorch’s Dynamic computation graph.\n",
        "    with torch.no_grad():\n",
        "      a-= lr * a.grad\n",
        "      b.sub_(lr * b.grad)\n",
        "    # Lets print a and b after the backward pass for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "      print(\"a and b after backward pass\" , a,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number = 0\n",
            "a and b before backward pass tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-3.3881], device='cuda:0')\n",
            "b's gradient =  tensor([-1.9439], device='cuda:0')\n",
            "a and b after backward pass tensor([0.5328], device='cuda:0', requires_grad=True) tensor([0.3335], device='cuda:0', requires_grad=True)\n",
            "epoch number = 100\n",
            "a and b before backward pass tensor([0.2229], device='cuda:0', requires_grad=True) tensor([0.1810], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-4.1505], device='cuda:0')\n",
            "b's gradient =  tensor([-1.8718], device='cuda:0')\n",
            "a and b after backward pass tensor([0.6379], device='cuda:0', requires_grad=True) tensor([0.3682], device='cuda:0', requires_grad=True)\n",
            "epoch number = 200\n",
            "a and b before backward pass tensor([0.2240], device='cuda:0', requires_grad=True) tensor([0.3068], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-4.8702], device='cuda:0')\n",
            "b's gradient =  tensor([-1.7955], device='cuda:0')\n",
            "a and b after backward pass tensor([0.7110], device='cuda:0', requires_grad=True) tensor([0.4864], device='cuda:0', requires_grad=True)\n",
            "epoch number = 300\n",
            "a and b before backward pass tensor([0.2004], device='cuda:0', requires_grad=True) tensor([0.5092], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-5.5295], device='cuda:0')\n",
            "b's gradient =  tensor([-1.7378], device='cuda:0')\n",
            "a and b after backward pass tensor([0.7533], device='cuda:0', requires_grad=True) tensor([0.6830], device='cuda:0', requires_grad=True)\n",
            "epoch number = 400\n",
            "a and b before backward pass tensor([0.1578], device='cuda:0', requires_grad=True) tensor([0.7758], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-6.1127], device='cuda:0')\n",
            "b's gradient =  tensor([-1.7185], device='cuda:0')\n",
            "a and b after backward pass tensor([0.7690], device='cuda:0', requires_grad=True) tensor([0.9476], device='cuda:0', requires_grad=True)\n",
            "epoch number = 500\n",
            "a and b before backward pass tensor([0.1038], device='cuda:0', requires_grad=True) tensor([1.0900], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-6.6066], device='cuda:0')\n",
            "b's gradient =  tensor([-1.7537], device='cuda:0')\n",
            "a and b after backward pass tensor([0.7645], device='cuda:0', requires_grad=True) tensor([1.2654], device='cuda:0', requires_grad=True)\n",
            "epoch number = 600\n",
            "a and b before backward pass tensor([0.0476], device='cuda:0', requires_grad=True) tensor([1.4321], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-7.0014], device='cuda:0')\n",
            "b's gradient =  tensor([-1.8537], device='cuda:0')\n",
            "a and b after backward pass tensor([0.7478], device='cuda:0', requires_grad=True) tensor([1.6175], device='cuda:0', requires_grad=True)\n",
            "epoch number = 700\n",
            "a and b before backward pass tensor([-0.0010], device='cuda:0', requires_grad=True) tensor([1.7809], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-7.2911], device='cuda:0')\n",
            "b's gradient =  tensor([-2.0226], device='cuda:0')\n",
            "a and b after backward pass tensor([0.7281], device='cuda:0', requires_grad=True) tensor([1.9832], device='cuda:0', requires_grad=True)\n",
            "epoch number = 800\n",
            "a and b before backward pass tensor([-0.0321], device='cuda:0', requires_grad=True) tensor([2.1147], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-7.4737], device='cuda:0')\n",
            "b's gradient =  tensor([-2.2580], device='cuda:0')\n",
            "a and b after backward pass tensor([0.7153], device='cuda:0', requires_grad=True) tensor([2.3405], device='cuda:0', requires_grad=True)\n",
            "epoch number = 900\n",
            "a and b before backward pass tensor([-0.0366], device='cuda:0', requires_grad=True) tensor([2.4134], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-7.5511], device='cuda:0')\n",
            "b's gradient =  tensor([-2.5508], device='cuda:0')\n",
            "a and b after backward pass tensor([0.7185], device='cuda:0', requires_grad=True) tensor([2.6685], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ThkkFYjXjsep",
        "colab_type": "text"
      },
      "source": [
        "This ran successfully. But the values of a and b are wrong at 900th epoch and is getting worse. \n",
        "Our results from numpy exercise were very close to actual values after 1000 epochs. \n",
        "This is another issue due to Pytorch's computational graph. It keeps accumulating the gradient values.\n",
        "We need to tell it to let it go after an epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVQ82cjRkZA0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Now a and b are messed up again. So, I initialize them yet again. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ea9lKx5TkV6U",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "b5317a7e-62e0-4af5-dc60-eac9e99e4050"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "a, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.1940], device='cuda:0', requires_grad=True),\n",
              " tensor([0.1391], device='cuda:0', requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gFyLXbZykV6Y",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "45bfa001-8e16-4d5e-ed83-a2650a100821"
      },
      "source": [
        "print(a, b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ydACvB4TkV6b",
        "colab_type": "text"
      },
      "source": [
        "# Lets try something else now. We will reset the grads to zero after each epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VEJ_fAUnkRTR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3d56153b-1888-4de6-ba8c-8f1b92d45bdc"
      },
      "source": [
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "    \n",
        "    # Lets print a and b before the backward pass for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "      print(\"epoch number =\", epoch)\n",
        "      print(\"a and b before backward pass\" , a,b)\n",
        "\n",
        "    # We will not do this now like we did in Numpy notebook \n",
        "    # - https://github.com/manjunathrgithub/Simple-LR-Model-with-Numpy/blob/master/LR_Using_Numpy.ipynb\n",
        "    # a_grad = -2 * error.mean()\n",
        "    # b_grad = -2 * (x_tensor * error).mean()\n",
        "    \n",
        "    # We will tell PyTorch to do the back progagation to the beginning from the specified loss which is at the end. \n",
        "    loss.backward()\n",
        "    # Let's check the computed gradients...\n",
        "    # Lets print the gradients for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "        print(\"a's gradient = \" , a.grad) \n",
        "        print(\"b's gradient = \" , b.grad)\n",
        "    \n",
        "    # Let's try to update the parameters with the formula we know - parameters = parameters - learning rate* gradient(parameters wrto Loss function)\n",
        "    # We are telling Pytorch not to calculate gradients for steps within the \"with\"\n",
        "    with torch.no_grad():\n",
        "        a-= lr * a.grad\n",
        "        b.sub_(lr * b.grad)\n",
        "    \n",
        "    # Lets print a and b after the backward pass for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "        print(\"a and b after backward pass\" , a,b)\n",
        "\n",
        "    # We reset it to zero after each epoch\n",
        "    a.grad.zero_()\n",
        "    b.grad.zero_()\n",
        "    # Lets print a and b after the backward pass and after reset to zero for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "        print(\"a and b after backward pass after resetting grad to zero\" , a,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number = 0\n",
            "a and b before backward pass tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-3.3881], device='cuda:0')\n",
            "b's gradient =  tensor([-1.9439], device='cuda:0')\n",
            "a and b after backward pass tensor([0.5328], device='cuda:0', requires_grad=True) tensor([0.3335], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([0.5328], device='cuda:0', requires_grad=True) tensor([0.3335], device='cuda:0', requires_grad=True)\n",
            "epoch number = 100\n",
            "a and b before backward pass tensor([1.1479], device='cuda:0', requires_grad=True) tensor([1.7257], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0188], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0367], device='cuda:0')\n",
            "a and b after backward pass tensor([1.1460], device='cuda:0', requires_grad=True) tensor([1.7294], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.1460], device='cuda:0', requires_grad=True) tensor([1.7294], device='cuda:0', requires_grad=True)\n",
            "epoch number = 200\n",
            "a and b before backward pass tensor([1.0507], device='cuda:0', requires_grad=True) tensor([1.9159], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0041], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0080], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0503], device='cuda:0', requires_grad=True) tensor([1.9167], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0503], device='cuda:0', requires_grad=True) tensor([1.9167], device='cuda:0', requires_grad=True)\n",
            "epoch number = 300\n",
            "a and b before backward pass tensor([1.0295], device='cuda:0', requires_grad=True) tensor([1.9574], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0009], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0018], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0294], device='cuda:0', requires_grad=True) tensor([1.9576], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0294], device='cuda:0', requires_grad=True) tensor([1.9576], device='cuda:0', requires_grad=True)\n",
            "epoch number = 400\n",
            "a and b before backward pass tensor([1.0248], device='cuda:0', requires_grad=True) tensor([1.9664], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0002], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0004], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0248], device='cuda:0', requires_grad=True) tensor([1.9665], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0248], device='cuda:0', requires_grad=True) tensor([1.9665], device='cuda:0', requires_grad=True)\n",
            "epoch number = 500\n",
            "a and b before backward pass tensor([1.0238], device='cuda:0', requires_grad=True) tensor([1.9684], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([4.2574e-05], device='cuda:0')\n",
            "b's gradient =  tensor([-8.3295e-05], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0238], device='cuda:0', requires_grad=True) tensor([1.9684], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0238], device='cuda:0', requires_grad=True) tensor([1.9684], device='cuda:0', requires_grad=True)\n",
            "epoch number = 600\n",
            "a and b before backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9688], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([9.3249e-06], device='cuda:0')\n",
            "b's gradient =  tensor([-1.8163e-05], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9688], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9688], device='cuda:0', requires_grad=True)\n",
            "epoch number = 700\n",
            "a and b before backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9689], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([1.9097e-06], device='cuda:0')\n",
            "b's gradient =  tensor([-4.1103e-06], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9689], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9689], device='cuda:0', requires_grad=True)\n",
            "epoch number = 800\n",
            "a and b before backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([5.1083e-07], device='cuda:0')\n",
            "b's gradient =  tensor([-8.8313e-07], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "epoch number = 900\n",
            "a and b before backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([5.4762e-07], device='cuda:0')\n",
            "b's gradient =  tensor([-5.7358e-07], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32zdRNHFnI6a",
        "colab_type": "text"
      },
      "source": [
        "This looks good. Compare the gradient values for each epoch for this loop vs the one before. \n",
        "The gradients keep improving here and the values of a and b keep coming closer to actual values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WszQKhUjnYWO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "df3bc28b-dc2f-4c89-8e39-6d3195594e6f"
      },
      "source": [
        "a, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([1.0235], device='cuda:0', requires_grad=True),\n",
              " tensor([1.9690], device='cuda:0', requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZVE0WgJnbhl",
        "colab_type": "text"
      },
      "source": [
        "The predicted values are close to actual values. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ricudhFrTTd",
        "colab_type": "text"
      },
      "source": [
        "# Dynamic Computational Graph"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vm9ZzteUsemy",
        "colab_type": "text"
      },
      "source": [
        "Now a and b are not messed up. But I am resetting them to check the Dynamic Computational Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "a8_1lsnBsem0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "81b1b647-220e-46b3-eb08-b282c525eb80"
      },
      "source": [
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "a, b"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.1940], device='cuda:0', requires_grad=True),\n",
              " tensor([0.1391], device='cuda:0', requires_grad=True))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Zou6ih4bsem2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ba124f79-2f6f-41be-ff2b-345841f40c78"
      },
      "source": [
        "print(a, b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_OyFjC9HZqe",
        "colab_type": "text"
      },
      "source": [
        "Lets manually calculate the prediction, error and loss for epoch 0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfC4f1wPHX0Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "yhat = a + b * x_train_tensor\n",
        "error = y_train_tensor - yhat\n",
        "loss = (error ** 2).mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STJj_XoZIRbU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "outputId": "5dc2eacd-0a36-4d20-d172-1c7427dba170"
      },
      "source": [
        "make_dot(yhat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7efcc6ec62e8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"172pt\" height=\"171pt\"\n viewBox=\"0.00 0.00 171.50 171.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 167)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-167 167.5,-167 167.5,4 -4,4\"/>\n<!-- 139624134240632 -->\n<g id=\"node1\" class=\"node\">\n<title>139624134240632</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"118,-21 26,-21 26,0 118,0 118,-21\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139624134241080 -->\n<g id=\"node2\" class=\"node\">\n<title>139624134241080</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-92 0,-92 0,-57 54,-57 54,-92\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139624134241080&#45;&gt;139624134240632 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139624134241080&#45;&gt;139624134240632</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M39.535,-56.6724C45.4798,-48.2176 52.5878,-38.1085 58.6352,-29.5078\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5714,-31.4169 64.4601,-21.2234 55.8452,-27.3906 61.5714,-31.4169\"/>\n</g>\n<!-- 139624134239400 -->\n<g id=\"node3\" class=\"node\">\n<title>139624134239400</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-85 72.5,-85 72.5,-64 163.5,-64 163.5,-85\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-71.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139624134239400&#45;&gt;139624134240632 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139624134239400&#45;&gt;139624134240632</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.404,-63.9317C103.7191,-54.6309 93.821,-40.8597 85.7479,-29.6276\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.4395,-27.3753 79.761,-21.2979 82.7553,-31.4608 88.4395,-27.3753\"/>\n</g>\n<!-- 139624134240968 -->\n<g id=\"node4\" class=\"node\">\n<title>139624134240968</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"145,-163 91,-163 91,-128 145,-128 145,-163\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-135.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139624134240968&#45;&gt;139624134239400 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139624134240968&#45;&gt;139624134239400</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M118,-127.9494C118,-118.058 118,-105.6435 118,-95.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.5001,-95.0288 118,-85.0288 114.5001,-95.0289 121.5001,-95.0288\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfhwdcSwIXc7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 326
        },
        "outputId": "f1e2b60f-4733-4ba7-d28f-1d4694926061"
      },
      "source": [
        "make_dot(error)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7efcc6ec6eb8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"172pt\" height=\"228pt\"\n viewBox=\"0.00 0.00 171.50 228.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 224)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-224 167.5,-224 167.5,4 -4,4\"/>\n<!-- 139624134240408 -->\n<g id=\"node1\" class=\"node\">\n<title>139624134240408</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"117,-21 27,-21 27,0 117,0 117,-21\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139624134240632 -->\n<g id=\"node2\" class=\"node\">\n<title>139624134240632</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118,-78 26,-78 26,-57 118,-57 118,-78\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139624134240632&#45;&gt;139624134240408 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139624134240632&#45;&gt;139624134240408</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-56.7787C72,-49.6134 72,-39.9517 72,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-31.1732 72,-21.1732 68.5001,-31.1732 75.5001,-31.1732\"/>\n</g>\n<!-- 139624134241080 -->\n<g id=\"node3\" class=\"node\">\n<title>139624134241080</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-149 0,-149 0,-114 54,-114 54,-149\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139624134241080&#45;&gt;139624134240632 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139624134241080&#45;&gt;139624134240632</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M39.535,-113.6724C45.4798,-105.2176 52.5878,-95.1085 58.6352,-86.5078\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5714,-88.4169 64.4601,-78.2234 55.8452,-84.3906 61.5714,-88.4169\"/>\n</g>\n<!-- 139624134239400 -->\n<g id=\"node4\" class=\"node\">\n<title>139624134239400</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-142 72.5,-142 72.5,-121 163.5,-121 163.5,-142\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-128.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139624134239400&#45;&gt;139624134240632 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139624134239400&#45;&gt;139624134240632</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.404,-120.9317C103.7191,-111.6309 93.821,-97.8597 85.7479,-86.6276\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.4395,-84.3753 79.761,-78.2979 82.7553,-88.4608 88.4395,-84.3753\"/>\n</g>\n<!-- 139624134240968 -->\n<g id=\"node5\" class=\"node\">\n<title>139624134240968</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"145,-220 91,-220 91,-185 145,-185 145,-220\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-192.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139624134240968&#45;&gt;139624134239400 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139624134240968&#45;&gt;139624134239400</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M118,-184.9494C118,-175.058 118,-162.6435 118,-152.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.5001,-152.0288 118,-142.0288 114.5001,-152.0289 121.5001,-152.0288\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOnfpsQdIasq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "outputId": "c811cc40-2e67-43a1-f2f4-826f05eb09fd"
      },
      "source": [
        "make_dot(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<graphviz.dot.Digraph at 0x7efcc6e553c8>"
            ],
            "image/svg+xml": "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n<!-- Generated by graphviz version 2.40.1 (20161225.0304)\n -->\n<!-- Title: %3 Pages: 1 -->\n<svg width=\"172pt\" height=\"342pt\"\n viewBox=\"0.00 0.00 171.50 342.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 338)\">\n<title>%3</title>\n<polygon fill=\"#ffffff\" stroke=\"transparent\" points=\"-4,4 -4,-338 167.5,-338 167.5,4 -4,4\"/>\n<!-- 139624133776552 -->\n<g id=\"node1\" class=\"node\">\n<title>139624133776552</title>\n<polygon fill=\"#caff70\" stroke=\"#000000\" points=\"121,-21 23,-21 23,0 121,0 121,-21\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-7.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MeanBackward0</text>\n</g>\n<!-- 139624133776160 -->\n<g id=\"node2\" class=\"node\">\n<title>139624133776160</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118.5,-78 25.5,-78 25.5,-57 118.5,-57 118.5,-78\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-64.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">PowBackward0</text>\n</g>\n<!-- 139624133776160&#45;&gt;139624133776552 -->\n<g id=\"edge1\" class=\"edge\">\n<title>139624133776160&#45;&gt;139624133776552</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-56.7787C72,-49.6134 72,-39.9517 72,-31.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-31.1732 72,-21.1732 68.5001,-31.1732 75.5001,-31.1732\"/>\n</g>\n<!-- 139624133775656 -->\n<g id=\"node3\" class=\"node\">\n<title>139624133775656</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"117,-135 27,-135 27,-114 117,-114 117,-135\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-121.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">SubBackward0</text>\n</g>\n<!-- 139624133775656&#45;&gt;139624133776160 -->\n<g id=\"edge2\" class=\"edge\">\n<title>139624133775656&#45;&gt;139624133776160</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-113.7787C72,-106.6134 72,-96.9517 72,-88.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-88.1732 72,-78.1732 68.5001,-88.1732 75.5001,-88.1732\"/>\n</g>\n<!-- 139624133776440 -->\n<g id=\"node4\" class=\"node\">\n<title>139624133776440</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"118,-192 26,-192 26,-171 118,-171 118,-192\"/>\n<text text-anchor=\"middle\" x=\"72\" y=\"-178.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">AddBackward0</text>\n</g>\n<!-- 139624133776440&#45;&gt;139624133775656 -->\n<g id=\"edge3\" class=\"edge\">\n<title>139624133776440&#45;&gt;139624133775656</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M72,-170.7787C72,-163.6134 72,-153.9517 72,-145.3097\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"75.5001,-145.1732 72,-135.1732 68.5001,-145.1732 75.5001,-145.1732\"/>\n</g>\n<!-- 139624133777056 -->\n<g id=\"node5\" class=\"node\">\n<title>139624133777056</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"54,-263 0,-263 0,-228 54,-228 54,-263\"/>\n<text text-anchor=\"middle\" x=\"27\" y=\"-235.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139624133777056&#45;&gt;139624133776440 -->\n<g id=\"edge4\" class=\"edge\">\n<title>139624133777056&#45;&gt;139624133776440</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M39.535,-227.6724C45.4798,-219.2176 52.5878,-209.1085 58.6352,-200.5078\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"61.5714,-202.4169 64.4601,-192.2234 55.8452,-198.3906 61.5714,-202.4169\"/>\n</g>\n<!-- 139624133777112 -->\n<g id=\"node6\" class=\"node\">\n<title>139624133777112</title>\n<polygon fill=\"#d3d3d3\" stroke=\"#000000\" points=\"163.5,-256 72.5,-256 72.5,-235 163.5,-235 163.5,-256\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-242.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\">MulBackward0</text>\n</g>\n<!-- 139624133777112&#45;&gt;139624133776440 -->\n<g id=\"edge5\" class=\"edge\">\n<title>139624133777112&#45;&gt;139624133776440</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M110.404,-234.9317C103.7191,-225.6309 93.821,-211.8597 85.7479,-200.6276\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"88.4395,-198.3753 79.761,-192.2979 82.7553,-202.4608 88.4395,-198.3753\"/>\n</g>\n<!-- 139624133777280 -->\n<g id=\"node7\" class=\"node\">\n<title>139624133777280</title>\n<polygon fill=\"#add8e6\" stroke=\"#000000\" points=\"145,-334 91,-334 91,-299 145,-299 145,-334\"/>\n<text text-anchor=\"middle\" x=\"118\" y=\"-306.4\" font-family=\"Times,serif\" font-size=\"12.00\" fill=\"#000000\"> (1)</text>\n</g>\n<!-- 139624133777280&#45;&gt;139624133777112 -->\n<g id=\"edge6\" class=\"edge\">\n<title>139624133777280&#45;&gt;139624133777112</title>\n<path fill=\"none\" stroke=\"#000000\" d=\"M118,-298.9494C118,-289.058 118,-276.6435 118,-266.2693\"/>\n<polygon fill=\"#000000\" stroke=\"#000000\" points=\"121.5001,-266.0288 118,-256.0288 114.5001,-266.0289 121.5001,-266.0288\"/>\n</g>\n</g>\n</svg>\n"
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-zCku7fjI3Xm",
        "colab_type": "text"
      },
      "source": [
        "**Blue box** - This is for the tensors that are used as parameters i.e. a and b and we have set requires_grad = True for them.\n",
        "\n",
        "**Grey box** - This indicates some operation that involves a gradient-computing (like a or b) tensor and/or its dependencies.\n",
        "\n",
        "**Green box** - This indicates the starting point of the gradient calculation for the backward pass. This and grey boxes are the places where gradients are calculated. \n",
        "\n",
        "Note that there are no special mentions for x in the forward pass of the graph because it is **not** a tensor for which we compute gradients. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OS709WwAMJSD",
        "colab_type": "text"
      },
      "source": [
        "# Lets torch it more.. We used pytorch to calculate the gradients before using the .backward function.\n",
        "# Lets use pytorch now to do the parameters = parameters - learning rate * gradients which is updating the weights or parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXkcAeOSM6lE",
        "colab_type": "text"
      },
      "source": [
        "Generally we do not update the weights/parameters manually since there will be a large number of them. We have to use the optim class of Pytorch."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eb2-lhlHOuYy",
        "colab_type": "text"
      },
      "source": [
        "In below code, we are basically using the optim code to update parameters through SGD (in this case since entire batch of data is used it works as Batch Gradient Descent). In real life, this would actually work as a Mini Batch Gradient Descent since mini batches of data are sent at a time in each epoch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ogZKkgbcM5Ve",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3739090f-f7d3-4f97-d0a4-74489bdf5cdf"
      },
      "source": [
        "#Resetting a and b again\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "a, b\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Define a SGD optimizer to update the parameters\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    error = y_train_tensor - yhat\n",
        "    loss = (error ** 2).mean()\n",
        "    \n",
        "    # Lets print a and b before the backward pass for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "      print(\"epoch number =\", epoch)\n",
        "      print(\"a and b before backward pass\" , a,b)\n",
        "\n",
        "    # We will not do this now like we did in Numpy notebook \n",
        "    # - https://github.com/manjunathrgithub/Simple-LR-Model-with-Numpy/blob/master/LR_Using_Numpy.ipynb\n",
        "    # a_grad = -2 * error.mean()\n",
        "    # b_grad = -2 * (x_tensor * error).mean()\n",
        "    \n",
        "    # We will tell PyTorch to do the back progagation to the beginning from the specified loss which is at the end. \n",
        "    loss.backward()\n",
        "    # Let's check the computed gradients...\n",
        "    # Lets print the gradients for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "        print(\"a's gradient = \" , a.grad) \n",
        "        print(\"b's gradient = \" , b.grad)\n",
        "    \n",
        "    # Let's try to update the parameters with the formula we know - parameters = parameters - learning rate* gradient(parameters wrto Loss function)\n",
        "    # We are telling Pytorch not to calculate gradients for steps within the \"with\"\n",
        "    #with torch.no_grad():\n",
        "    #    a-= lr * a.grad\n",
        "    #   b.sub_(lr * b.grad)\n",
        "\n",
        "    # We will use optimizer to update the parameters. \n",
        "    optimizer.step()\n",
        "    \n",
        "    # Lets print a and b after the backward pass for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "        print(\"a and b after backward pass\" , a,b)\n",
        "\n",
        "    # We reset it to zero after each epoch\n",
        "    #a.grad.zero_()\n",
        "    #b.grad.zero_()\n",
        "\n",
        "    # We will use optimizer to reset the gradients to zero. \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Lets print a and b after the backward pass and after reset to zero for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "        print(\"a and b after backward pass after resetting grad to zero\" , a,b)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number = 0\n",
            "a and b before backward pass tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-3.3881], device='cuda:0')\n",
            "b's gradient =  tensor([-1.9439], device='cuda:0')\n",
            "a and b after backward pass tensor([0.5328], device='cuda:0', requires_grad=True) tensor([0.3335], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([0.5328], device='cuda:0', requires_grad=True) tensor([0.3335], device='cuda:0', requires_grad=True)\n",
            "epoch number = 100\n",
            "a and b before backward pass tensor([1.1479], device='cuda:0', requires_grad=True) tensor([1.7257], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0188], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0367], device='cuda:0')\n",
            "a and b after backward pass tensor([1.1460], device='cuda:0', requires_grad=True) tensor([1.7294], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.1460], device='cuda:0', requires_grad=True) tensor([1.7294], device='cuda:0', requires_grad=True)\n",
            "epoch number = 200\n",
            "a and b before backward pass tensor([1.0507], device='cuda:0', requires_grad=True) tensor([1.9159], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0041], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0080], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0503], device='cuda:0', requires_grad=True) tensor([1.9167], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0503], device='cuda:0', requires_grad=True) tensor([1.9167], device='cuda:0', requires_grad=True)\n",
            "epoch number = 300\n",
            "a and b before backward pass tensor([1.0295], device='cuda:0', requires_grad=True) tensor([1.9574], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0009], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0018], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0294], device='cuda:0', requires_grad=True) tensor([1.9576], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0294], device='cuda:0', requires_grad=True) tensor([1.9576], device='cuda:0', requires_grad=True)\n",
            "epoch number = 400\n",
            "a and b before backward pass tensor([1.0248], device='cuda:0', requires_grad=True) tensor([1.9664], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0002], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0004], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0248], device='cuda:0', requires_grad=True) tensor([1.9665], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0248], device='cuda:0', requires_grad=True) tensor([1.9665], device='cuda:0', requires_grad=True)\n",
            "epoch number = 500\n",
            "a and b before backward pass tensor([1.0238], device='cuda:0', requires_grad=True) tensor([1.9684], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([4.2574e-05], device='cuda:0')\n",
            "b's gradient =  tensor([-8.3295e-05], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0238], device='cuda:0', requires_grad=True) tensor([1.9684], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0238], device='cuda:0', requires_grad=True) tensor([1.9684], device='cuda:0', requires_grad=True)\n",
            "epoch number = 600\n",
            "a and b before backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9688], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([9.3249e-06], device='cuda:0')\n",
            "b's gradient =  tensor([-1.8163e-05], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9688], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9688], device='cuda:0', requires_grad=True)\n",
            "epoch number = 700\n",
            "a and b before backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9689], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([1.9097e-06], device='cuda:0')\n",
            "b's gradient =  tensor([-4.1103e-06], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9689], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9689], device='cuda:0', requires_grad=True)\n",
            "epoch number = 800\n",
            "a and b before backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([5.1083e-07], device='cuda:0')\n",
            "b's gradient =  tensor([-8.8313e-07], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "epoch number = 900\n",
            "a and b before backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([5.4762e-07], device='cuda:0')\n",
            "b's gradient =  tensor([-5.7358e-07], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a and b after backward pass after resetting grad to zero tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Lu5jU3KPRby",
        "colab_type": "text"
      },
      "source": [
        "The output looks good and we used Pytorch's optim to update parameters and also reset the gradient after each epoch. Good going..!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9pg_7HfpPcw_",
        "colab_type": "text"
      },
      "source": [
        "# What else is our handwritten code ? Prediction expression, Error and Loss calculations."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb0w-kcuQGs5",
        "colab_type": "text"
      },
      "source": [
        "Lets work on Loss and Error first. \n",
        "\n",
        "Pytorch has many Loss functions and we have to use the appropriate ones based on the need. \n",
        "\n",
        "In this example, we are using MSE and we can use nn.MSELoss class for creating the loss function. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8XEjAXQQJ4z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "50d916c1-55a4-472c-b6c0-ccbf89b58241"
      },
      "source": [
        "#Resetting a and b again\n",
        "\n",
        "torch.manual_seed(42)\n",
        "a = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "b = torch.randn(1, requires_grad=True, dtype=torch.float, device=device)\n",
        "a, b\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Define a SGD optimizer to update the parameters\n",
        "optimizer = optim.SGD([a, b], lr=lr)\n",
        "loss_func = nn.MSELoss(reduction='mean')\n",
        "# reduction = 'mean' basically says you aggregate the losses by mean. \n",
        "# reduction can also be sum in which case it is SSE. Sum Squared Error.\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    yhat = a + b * x_train_tensor\n",
        "    # error = y_train_tensor - yhat\n",
        "    #loss = (error ** 2).mean()\n",
        "    # We commented the loss calculation and error calculation since \n",
        "    # both will be taken care of by loss_func defined above. \n",
        "    loss = loss_func(y_train_tensor, yhat)\n",
        "    \n",
        "    # Lets print a and b before the backward pass for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "      print(\"epoch number =\", epoch)\n",
        "      print(\"a and b before backward pass\" , a,b)\n",
        "\n",
        "    # We will not do this now like we did in Numpy notebook \n",
        "    # - https://github.com/manjunathrgithub/Simple-LR-Model-with-Numpy/blob/master/LR_Using_Numpy.ipynb\n",
        "    # a_grad = -2 * error.mean()\n",
        "    # b_grad = -2 * (x_tensor * error).mean()\n",
        "    \n",
        "    # We will tell PyTorch to do the back progagation to the beginning from the specified loss which is at the end. \n",
        "    loss.backward()\n",
        "    # Let's check the computed gradients...\n",
        "    # Lets print the gradients for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "        print(\"a's gradient = \" , a.grad) \n",
        "        print(\"b's gradient = \" , b.grad)\n",
        "    \n",
        "    # Let's try to update the parameters with the formula we know - parameters = parameters - learning rate* gradient(parameters wrto Loss function)\n",
        "    # We are telling Pytorch not to calculate gradients for steps within the \"with\"\n",
        "    #with torch.no_grad():\n",
        "    #    a-= lr * a.grad\n",
        "    #   b.sub_(lr * b.grad)\n",
        "\n",
        "    # We will use optimizer to update the parameters. \n",
        "    optimizer.step()\n",
        "    \n",
        "    # Lets print a and b after the backward pass for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "        print(\"a and b after backward pass\" , a,b)\n",
        "\n",
        "    # We reset it to zero after each epoch\n",
        "    #a.grad.zero_()\n",
        "    #b.grad.zero_()\n",
        "\n",
        "    # We will use optimizer to reset the gradients to zero. \n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # Lets print a and b after the backward pass and after reset to zero for certain epochs only.\n",
        "    if(epoch%100==0):\n",
        "        print(\"a and b after backward and zeroing grad\" , a,b)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch number = 0\n",
            "a and b before backward pass tensor([0.1940], device='cuda:0', requires_grad=True) tensor([0.1391], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([-3.3881], device='cuda:0')\n",
            "b's gradient =  tensor([-1.9439], device='cuda:0')\n",
            "a and b after backward pass tensor([0.5328], device='cuda:0', requires_grad=True) tensor([0.3335], device='cuda:0', requires_grad=True)\n",
            "a and b after backward and zeroing grad tensor([0.5328], device='cuda:0', requires_grad=True) tensor([0.3335], device='cuda:0', requires_grad=True)\n",
            "epoch number = 100\n",
            "a and b before backward pass tensor([1.1479], device='cuda:0', requires_grad=True) tensor([1.7257], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0188], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0367], device='cuda:0')\n",
            "a and b after backward pass tensor([1.1460], device='cuda:0', requires_grad=True) tensor([1.7294], device='cuda:0', requires_grad=True)\n",
            "a and b after backward and zeroing grad tensor([1.1460], device='cuda:0', requires_grad=True) tensor([1.7294], device='cuda:0', requires_grad=True)\n",
            "epoch number = 200\n",
            "a and b before backward pass tensor([1.0507], device='cuda:0', requires_grad=True) tensor([1.9159], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0041], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0080], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0503], device='cuda:0', requires_grad=True) tensor([1.9167], device='cuda:0', requires_grad=True)\n",
            "a and b after backward and zeroing grad tensor([1.0503], device='cuda:0', requires_grad=True) tensor([1.9167], device='cuda:0', requires_grad=True)\n",
            "epoch number = 300\n",
            "a and b before backward pass tensor([1.0295], device='cuda:0', requires_grad=True) tensor([1.9574], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0009], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0018], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0294], device='cuda:0', requires_grad=True) tensor([1.9576], device='cuda:0', requires_grad=True)\n",
            "a and b after backward and zeroing grad tensor([1.0294], device='cuda:0', requires_grad=True) tensor([1.9576], device='cuda:0', requires_grad=True)\n",
            "epoch number = 400\n",
            "a and b before backward pass tensor([1.0248], device='cuda:0', requires_grad=True) tensor([1.9664], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([0.0002], device='cuda:0')\n",
            "b's gradient =  tensor([-0.0004], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0248], device='cuda:0', requires_grad=True) tensor([1.9665], device='cuda:0', requires_grad=True)\n",
            "a and b after backward and zeroing grad tensor([1.0248], device='cuda:0', requires_grad=True) tensor([1.9665], device='cuda:0', requires_grad=True)\n",
            "epoch number = 500\n",
            "a and b before backward pass tensor([1.0238], device='cuda:0', requires_grad=True) tensor([1.9684], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([4.2574e-05], device='cuda:0')\n",
            "b's gradient =  tensor([-8.3295e-05], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0238], device='cuda:0', requires_grad=True) tensor([1.9684], device='cuda:0', requires_grad=True)\n",
            "a and b after backward and zeroing grad tensor([1.0238], device='cuda:0', requires_grad=True) tensor([1.9684], device='cuda:0', requires_grad=True)\n",
            "epoch number = 600\n",
            "a and b before backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9688], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([9.3249e-06], device='cuda:0')\n",
            "b's gradient =  tensor([-1.8163e-05], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9688], device='cuda:0', requires_grad=True)\n",
            "a and b after backward and zeroing grad tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9688], device='cuda:0', requires_grad=True)\n",
            "epoch number = 700\n",
            "a and b before backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9689], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([1.9097e-06], device='cuda:0')\n",
            "b's gradient =  tensor([-4.1103e-06], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9689], device='cuda:0', requires_grad=True)\n",
            "a and b after backward and zeroing grad tensor([1.0236], device='cuda:0', requires_grad=True) tensor([1.9689], device='cuda:0', requires_grad=True)\n",
            "epoch number = 800\n",
            "a and b before backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([5.1083e-07], device='cuda:0')\n",
            "b's gradient =  tensor([-8.8313e-07], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a and b after backward and zeroing grad tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "epoch number = 900\n",
            "a and b before backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a's gradient =  tensor([5.4762e-07], device='cuda:0')\n",
            "b's gradient =  tensor([-5.7358e-07], device='cuda:0')\n",
            "a and b after backward pass tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n",
            "a and b after backward and zeroing grad tensor([1.0235], device='cuda:0', requires_grad=True) tensor([1.9690], device='cuda:0', requires_grad=True)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3OJ-lae8SeK-",
        "colab_type": "text"
      },
      "source": [
        "# Alright.. Loss calculated using Pytorch. What next ? \n",
        "\n",
        "#Lets tackle the remaining manually written expression. \n",
        "\n",
        "#***The Prediction logic or the Model*** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qR2u1YI_DPg",
        "colab_type": "text"
      },
      "source": [
        "For the model, we need to use the Module Class of Pytorch. We should create a new class which inherits from the Module class.\n",
        "\n",
        "It needs to have two mandatory methods apart from any other methods as required for the problem at hand -  \n",
        "__init__(self) - As the name says this is for the initialization. Setting up of the parameters. In this case of LR, we have a and b\n",
        "\n",
        "forward(self, x) - The method which does the actual prediction logic. \n",
        "\n",
        "Pytorch Module class is defined such that the forward method works as the core method of the class. \n",
        "\n",
        "When the class is called like a function, the forward method is invoked. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zoTg0MytA3qX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Lets define the class as mentioned earlier which inherits the nn.Module Pytorch class\n",
        "\n",
        "class MyLRModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        # To make \"a\" and \"b\" real parameters of the model, we need to wrap them in nn.Parameter\n",
        "        self.a = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "        self.b = nn.Parameter(torch.randn(1, requires_grad=True, dtype=torch.float))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        # Computes the predictions and in this case it is a + bx\n",
        "        return self.a + self.b * x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RnPWNP34TTIU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "103d5137-e560-40fb-c3d3-c36dd5567ebc"
      },
      "source": [
        "# The class has a and b defined. Also removing the print statements within the epochs loop. \n",
        "\n",
        "#Keeping the seed same as before. This has to be done before defining the model. \n",
        "torch.manual_seed(42)\n",
        "\n",
        "# Now we can create a model and send it to the device. Model should be on the same device as the parameters.\n",
        "model = MyLRModel().to(device)\n",
        "\n",
        "\n",
        "# To print the values of a and b , we use state_dict() method.\n",
        "print(model.state_dict())\n",
        "\n",
        "lr = 1e-1\n",
        "n_epochs = 1000\n",
        "\n",
        "# Define a SGD optimizer to update the parameters. Note that parameters are now passed via model.parameters() and not manually.\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr)\n",
        "loss_func = nn.MSELoss(reduction='mean')\n",
        "# reduction = 'mean' basically says you aggregate the losses by mean. \n",
        "# reduction can also be sum in which case it is SSE. Sum Squared Error.\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    # This is to tell Pytorch that model should be in training mode at this time and not evaluation mode. \n",
        "    # The model behavior might change in different modes. \n",
        "    model.train() \n",
        "\n",
        "    yhat = model(x_train_tensor)\n",
        "\n",
        "    loss = loss_func(y_train_tensor, yhat)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "# To print the values of a and b after all epochs, we use state_dict() method.\n",
        "print(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('a', tensor([0.3367], device='cuda:0')), ('b', tensor([0.1288], device='cuda:0'))])\n",
            "OrderedDict([('a', tensor([1.0235], device='cuda:0')), ('b', tensor([1.9690], device='cuda:0'))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f1zWFj3IVI7",
        "colab_type": "text"
      },
      "source": [
        "Output same as before. We have 5 statements in the loop. \n",
        "\n",
        "    yhat = model(x_train_tensor)\n",
        "\n",
        "    loss = loss_func(y_train_tensor, yhat)\n",
        "\n",
        "    loss.backward()\n",
        "\n",
        "    optimizer.step()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "Can we refactor these ?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tl3fRoxzSkXM",
        "colab_type": "text"
      },
      "source": [
        "Lets refactor the training steps. Here, we just put all the code that kept repeating in the epoch loop in a method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dL9wQ0ER1H7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "da0d5465-e721-4470-bdf2-66939043bad1"
      },
      "source": [
        "def make_train_step(model, loss_fn, optimizer):\n",
        "    # Builds function that performs a step in the train loop\n",
        "    def train_step(x, y):\n",
        "        # Sets model to training mode\n",
        "        model.train()\n",
        "        # Makes predictions\n",
        "        yhat = model(x)\n",
        "        # Computes loss\n",
        "        loss = loss_func(y, yhat)\n",
        "        # Computes gradients\n",
        "        loss.backward()\n",
        "        # Updates parameters and zeroes gradients\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        # Returns the loss\n",
        "        return loss.item()\n",
        "    \n",
        "    # Returns the function that will be called inside the train loop\n",
        "    return train_step\n",
        "\n",
        "\n",
        "# Creates the train_step function for our model, loss function and optimizer\n",
        "train_step = make_train_step(model, loss_func, optimizer)\n",
        "losses = []\n",
        "\n",
        "# For each epoch...\n",
        "for epoch in range(n_epochs):\n",
        "    # Performs one train step and returns the corresponding loss\n",
        "    loss = train_step(x_train_tensor, y_train_tensor)\n",
        "    losses.append(loss)\n",
        "    \n",
        "# Checks model's parameters\n",
        "print(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('a', tensor([1.0235], device='cuda:0')), ('b', tensor([1.9690], device='cuda:0'))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6S8o4lFUJzS",
        "colab_type": "text"
      },
      "source": [
        "In real life, data will not be so simple. \n",
        "\n",
        "Therefore we pass data as (features, labels) to Pytorch\n",
        "\n",
        "features are inputs and labels are outputs. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5ef_fP6ZB2D",
        "colab_type": "text"
      },
      "source": [
        " For this we use the Dataset class of Pytorch. Below we see a custom Dataset class that we defined by inheriting the Pytorch's Dataset class as well as TensorDataset class of Pytorch\n",
        "\n",
        "Any dataset returns three things, (x,y) , a way to index through x,y and length(x) "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xb32BPPWU0n-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "44378a9a-061b-4865-b9e3-4847317d05f0"
      },
      "source": [
        "from torch.utils.data import Dataset, TensorDataset\n",
        "\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, x_tensor, y_tensor):\n",
        "        self.x = x_tensor\n",
        "        self.y = y_tensor\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        return (self.x[index], self.y[index])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.x)\n",
        "\n",
        "\n",
        "x_train_tensor = torch.from_numpy(x_train).float()\n",
        "y_train_tensor = torch.from_numpy(y_train).float()\n",
        "\n",
        "train_data = CustomDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])\n",
        "type(train_data)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([0.7713]), tensor([2.4745]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "__main__.CustomDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_KxJ0DQYyoL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6ca361ce-6071-4601-bd74-870ee9e66bb8"
      },
      "source": [
        "train_data = TensorDataset(x_train_tensor, y_train_tensor)\n",
        "print(train_data[0])\n",
        "type(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(tensor([0.7713]), tensor([2.4745]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.utils.data.dataset.TensorDataset"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-R_rPFA_q8q6",
        "colab_type": "text"
      },
      "source": [
        "The outputs of our Custom Dataset class and TensorDataset class are the same. \n",
        "This is because we are doing exactly what the TensorDataset will do although our class will not have other bells and whistles which TensorDataset class will have."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_-KOZyQr6rg",
        "colab_type": "text"
      },
      "source": [
        "Okay.. What next ?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PqOEcGLh9jwd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ee83ab4a-972d-438a-8be1-d5c44bc9a438"
      },
      "source": [
        "len(x_train_tensor) , type(x_train_tensor), len(train_data), type(train_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(80, torch.Tensor, 80, torch.utils.data.dataset.TensorDataset)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PkliyORA-H2Y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4c023b0b-7256-482d-9a43-50cbfae49f9d"
      },
      "source": [
        "len(x_val), type(x_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, numpy.ndarray)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fJGTh3P9-ty0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_valid_tensor = torch.from_numpy(x_val).float()\n",
        "y_valid_tensor = torch.from_numpy(y_val).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "525TBE7v-jOP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_data = TensorDataset(x_valid_tensor, y_valid_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dXc2NEJJ-1Yo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "485977e3-8758-4a4d-e45c-d6a9af811562"
      },
      "source": [
        "len(x_valid_tensor), type(x_valid_tensor), len(valid_data), type(valid_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(20, torch.Tensor, 20, torch.utils.data.dataset.TensorDataset)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UFJB09Br8-8",
        "colab_type": "text"
      },
      "source": [
        "In the above cells, we created Train and Valid Datasets using Pytorch TensorDataset class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Cp_dnRi_mSG",
        "colab_type": "text"
      },
      "source": [
        "Also note that these Datasets are on cpu and not the GPU. We will get to know the reason for this once we understand Dataloaders\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKtNxe6xASYo",
        "colab_type": "text"
      },
      "source": [
        "Before that lets try to push the dataset to GPU.. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wq9lEPx_24W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "4af3792a-2cc4-4742-86cd-fa9b613af9d4"
      },
      "source": [
        "train_data.to(device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-9b29ccbff29d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'TensorDataset' object has no attribute 'to'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dZMtOs-Y_0b4",
        "colab_type": "text"
      },
      "source": [
        "Ahh... It fails.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6pmQ3lfBO5P",
        "colab_type": "text"
      },
      "source": [
        "Lets see what these Dataloaders are. Generally data is sent to GPU and to the training loop in mini batches. Dataloader is a class which can store the dataset and allows to fetch mini batches of data via iteration. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-5t6sKTAcBy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_loader = DataLoader(dataset=train_data, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q7UXv3JMB7CD",
        "colab_type": "text"
      },
      "source": [
        "Below gives a mini batch of data from train_data dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zl0ZYex5BuVE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544
        },
        "outputId": "b0aa1750-a954-4784-e197-ed9acff16e88"
      },
      "source": [
        "next(iter(train_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.9507],\n",
              "         [0.5427],\n",
              "         [0.1409],\n",
              "         [0.3745],\n",
              "         [0.1987],\n",
              "         [0.8948],\n",
              "         [0.7722],\n",
              "         [0.7852],\n",
              "         [0.5248],\n",
              "         [0.2809],\n",
              "         [0.1159],\n",
              "         [0.0740],\n",
              "         [0.1849],\n",
              "         [0.4561],\n",
              "         [0.7608],\n",
              "         [0.1560]]), tensor([[2.8715],\n",
              "         [2.2161],\n",
              "         [1.1211],\n",
              "         [1.7578],\n",
              "         [1.2654],\n",
              "         [2.7393],\n",
              "         [2.4208],\n",
              "         [2.5283],\n",
              "         [2.0167],\n",
              "         [1.5846],\n",
              "         [1.1603],\n",
              "         [1.1713],\n",
              "         [1.5888],\n",
              "         [1.7706],\n",
              "         [2.4970],\n",
              "         [1.2901]])]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKiz4gtOCBxc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dde9e182-7a35-4b7f-9699-3c6cd7c385de"
      },
      "source": [
        "len(next(iter(train_loader.batch_sampler)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyI_gOV4DW09",
        "colab_type": "text"
      },
      "source": [
        "Above cell show the size of one iteration of the Dataloader. It is 16 i.e the size we specified. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnDkuRzlCVBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bb6d9b70-cb1d-4bbf-fdc4-857618fa051e"
      },
      "source": [
        "train_loader.batch_size"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRDAVubkCcKE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b5eedda1-6e90-410f-fdf9-e5eb16715b27"
      },
      "source": [
        "train_loader.dataset[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.7713]), tensor([2.4745]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX02WQVYCnaE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a14255d5-4150-4d88-b6dc-5f79df6c87e1"
      },
      "source": [
        "train_data[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([0.7713]), tensor([2.4745]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9wkMMvuDgAP",
        "colab_type": "text"
      },
      "source": [
        "Above cells show the value of the index 0 in dataset from within the Loader as well as direclty from the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vk0U_44QD_3H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cd930e5-74ee-457c-8627-e64b3890d555"
      },
      "source": [
        "losses = []\n",
        "train_step = make_train_step(model, loss_func, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        # The dataset, dataloader and its mini-batches all resides in the CPU for now.\n",
        "        # Lets send those mini-batches to the GPU in below steps\n",
        "        # Model is already in GPU\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "        \n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        losses.append(loss)\n",
        "        \n",
        "print(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('a', tensor([1.0242], device='cuda:0')), ('b', tensor([1.9682], device='cuda:0'))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPHlneWvEjlB",
        "colab_type": "text"
      },
      "source": [
        "Well, we added an extra loop and it took slightly higher time to finish than our previous trials."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azo57I6JEuhG",
        "colab_type": "text"
      },
      "source": [
        "However, this is required in real life, because the data will be huge and cannot be loaded into GPU at once. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MFCQXH5JE3EP",
        "colab_type": "text"
      },
      "source": [
        "If you remember, we split the data 80:20 as train and valid in the beginning of this notebook. \n",
        "\n",
        "However, we generally use Pytorch's feature to split the data into train and valid (random split) or we have data split as training and validation data using some functional rule beforehand."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YMe5Ky3QF5i9",
        "colab_type": "text"
      },
      "source": [
        "We have trained the model, but we need to validate it. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "29eJ6BtQF99e",
        "colab_type": "text"
      },
      "source": [
        "For that we use the validation dataloader-> dataset-> data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QiW0-4GXGynC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "valid_loader = DataLoader(dataset=valid_data, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDDW6zyjGFwy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3d4b7993-8bd4-4089-f306-b6af9a34573b"
      },
      "source": [
        "losses = []\n",
        "val_losses = []\n",
        "train_step = make_train_step(model, loss_func, optimizer)\n",
        "\n",
        "for epoch in range(n_epochs):\n",
        "    for x_batch, y_batch in train_loader:\n",
        "        x_batch = x_batch.to(device)\n",
        "        y_batch = y_batch.to(device)\n",
        "\n",
        "        loss = train_step(x_batch, y_batch)\n",
        "        losses.append(loss)\n",
        "        \n",
        "    with torch.no_grad():\n",
        "        for x_val, y_val in valid_loader:\n",
        "            x_val = x_val.to(device)\n",
        "            y_val = y_val.to(device)\n",
        "            \n",
        "            model.eval()\n",
        "\n",
        "            yhat = model(x_val)\n",
        "            val_loss = loss_func(y_val, yhat)\n",
        "            val_losses.append(val_loss.item())\n",
        "\n",
        "print(model.state_dict())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "OrderedDict([('a', tensor([1.0290], device='cuda:0')), ('b', tensor([1.9720], device='cuda:0'))])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yPK_B-AwHi8y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "3912a884-3ce7-4905-e195-962b04f5a347"
      },
      "source": [
        "len(val_losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ipe2hZ4RLae7",
        "colab_type": "text"
      },
      "source": [
        "2000. How did this number come ?\n",
        " valid data length (see first few lines of notebook) which is 20 / 16 batch size = 2 (approx)\n",
        "\n",
        " 2 * number of epochs(1000) = 2000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qkAHR3-6HVRA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "7f556238-dc6c-4760-d810-6fafa9dea3be"
      },
      "source": [
        "val_losses[1990:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.00672027375549078,\n",
              " 0.017072057351469994,\n",
              " 0.010100197046995163,\n",
              " 0.004003560170531273,\n",
              " 0.008860822767019272,\n",
              " 0.007289723493158817,\n",
              " 0.007129967212677002,\n",
              " 0.015293894335627556,\n",
              " 0.0099174864590168,\n",
              " 0.00720137357711792]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB7sUqIiHtGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "bba3bc8f-ebdd-46c0-9e6d-d166e7ab7570"
      },
      "source": [
        "len(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELMYr6i9L1nF",
        "colab_type": "text"
      },
      "source": [
        "5000. How did this number come ?\n",
        " train data length (see first few lines of notebook) which is 80 / 16 batch size = 5\n",
        "\n",
        "5 * number of epochs(1000) = 5000"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kHhGcalQH1y9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "bfed9b7e-0db4-4d6a-d808-27afc9cc888d"
      },
      "source": [
        "losses[4990:]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.01098373532295227,\n",
              " 0.007446237839758396,\n",
              " 0.004498552531003952,\n",
              " 0.011742398142814636,\n",
              " 0.006587368436157703,\n",
              " 0.006659486331045628,\n",
              " 0.008902094326913357,\n",
              " 0.006174780428409576,\n",
              " 0.010141816921532154,\n",
              " 0.008895618841052055]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJ9SmUO1IBSV",
        "colab_type": "text"
      },
      "source": [
        "As you can see the final losses of train and valid data, training loss is slightly higher than validation loss. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nlIqWhBeJhf7",
        "colab_type": "text"
      },
      "source": [
        "OrderedDict([('a', tensor([1.0290], device='cuda:0')), ('b', tensor([1.9720], device='cuda:0'))])\n",
        "\n",
        "# This is the final prediction of the model which is pretty accurate, slightly more accurate than our numpy model -  https://github.com/manjunathrgithub/Simple-LR-Model-with-Numpy/blob/master/LR_Using_Numpy.ipynb"
      ]
    }
  ]
}