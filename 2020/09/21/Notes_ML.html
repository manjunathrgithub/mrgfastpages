<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Notes_ml</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-21T00:00:00-05:00" itemprop="datePublished">
        Sep 21, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <h1 id="types-of-ml">Types of ML</h1>

<p>Based on how they are classified, below are some classifications</p>

<ul>
  <li>
    <p>Whether or not they are trained with human supervision</p>

    <ul>
      <li>
        <p>Supervised</p>
      </li>
      <li>
        <p>Unsupervised</p>
      </li>
      <li>
        <p>Semi supervised</p>
      </li>
      <li>
        <p>Reinforcement Learning</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Whether or not they can learn incrementally on the fly</p>

    <ul>
      <li>
        <p>Online</p>
      </li>
      <li>
        <p>batch learning</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Whether they work by simply comparing new data points to known data points, or instead by detecting patterns in the training data and building a predictive model, much like scientists do</p>

    <ul>
      <li>
        <p>instance-based</p>
      </li>
      <li>
        <p>model-based learning</p>
      </li>
    </ul>
  </li>
</ul>

<h2 id="common-supervised-learning-algorithms">Common Supervised Learning Algorithms</h2>

<ul>
  <li>
    <p>k-Nearest Neighbors</p>
  </li>
  <li>
    <p>Linear Regression</p>
  </li>
  <li>
    <p>Logistic Regression</p>
  </li>
  <li>
    <p>Support Vector Machines (SVMs)</p>
  </li>
  <li>
    <p>Decision Trees and Random Forests</p>
  </li>
  <li>
    <p>Neural networks</p>
  </li>
</ul>

<h2 id="common-unsupervised-learning-algorithms">Common Unsupervised Learning Algorithms</h2>

<ul>
  <li>
    <p>Clustering</p>

    <ul>
      <li>
        <p>K-Means</p>
      </li>
      <li>
        <p>DBSCAN</p>
      </li>
      <li>
        <p>Hierarchical Cluster Analysis (HCA)</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Anomaly detection and novelty detection</p>

    <ul>
      <li>
        <p>One-class SVM</p>
      </li>
      <li>
        <p>Isolation Forest</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Visualization and dimensionality reduction</p>

    <ul>
      <li>
        <p>Principal Component Analysis (PCA)</p>
      </li>
      <li>
        <p>Kernel PCA</p>
      </li>
      <li>
        <p>Locally Linear Embedding (LLE)</p>
      </li>
      <li>
        <p>t-Distributed Stochastic Neighbor Embedding (t-SNE)</p>
      </li>
    </ul>
  </li>
  <li>
    <p>Association rule learning</p>

    <ul>
      <li>
        <p>Apriori</p>
      </li>
      <li>
        <p>Eclat</p>
      </li>
    </ul>
  </li>
</ul>

<h2 id="most-semi-supervised-learning-algorithms-are-combinations-of-unsupervised-and-supervised-algorithms">Most semi supervised learning algorithms are combinations of unsupervised and supervised algorithms</h2>

<p>For example, <em>deep belief networks</em> (DBNs) are based on unsupervised components called <em>restricted Boltzmann machines</em> (RBMs) stacked on top of one another. RBMs are trained sequentially in an unsupervised manner, and then the whole system is fine-tuned using supervised learning techniques.</p>

<h2 id="reinforcement-learning-algorithms">Reinforcement Learning Algorithms</h2>

<p>There are no common algorithms. These work on Reward and Penalties and the learning happens over time by running it on multiple real-life examples</p>

<ul>
  <li>
    <p>Algorithms which play Chess or Go are an example</p>
  </li>
  <li>
    <p>Programs used in Robots are another example</p>
  </li>
</ul>

<h2 id="batch-and-online-learning-algorithms">Batch and Online Learning algorithms</h2>

<p>As the name says there are algorithms which have to be trained offline i.e. Batch Algorithms and algorithms which can learn on the fly i.e. Online algorithms</p>

<h2 id="instance-vs-model-algorithms">Instance vs Model algorithms</h2>

<p>Depending on whether the algorithm uses learned instances to predict for new inputs like say Classification Algorithms (k-NearestNeighbors for example) or uses a Model like say Regression Algorithms where you have a line/plane.</p>

<h1 id="challenges-in-ml">Challenges in ML</h1>

<ul>
  <li>
    <p>Bad Data</p>
  </li>
  <li>
    <p>Bad Model</p>
  </li>
</ul>

<h2 id="what-to-do-with-the-bad-data-or-bad-model">What to do with the Bad data or Bad model?</h2>

<ul>
  <li>
    <p>Feature Selection</p>
  </li>
  <li>
    <p>Feature Extraction</p>
  </li>
  <li>
    <p>Regularization</p>
  </li>
  <li>
    <p>Hyperparameters</p>
  </li>
</ul>

<h2 id="data-load">Data Load</h2>

<p>Below function will be useful to get data from online datasets.</p>

<blockquote>
  <p><strong>import</strong> <strong>os</strong></p>

  <p><strong>import</strong> <strong>tarfile</strong></p>

  <p><strong>import</strong> <strong>urllib</strong></p>

  <p>DOWNLOAD_ROOT = “https://raw.githubusercontent.com/ageron/handson-ml2/master/”</p>

  <p>HOUSING_PATH = os.path.join(“datasets”, “housing”)</p>

  <p>HOUSING_URL = DOWNLOAD_ROOT + “datasets/housing/housing.tgz”</p>

  <p><strong>def</strong> fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):</p>

  <p>os.makedirs(housing_path, exist_ok=True)</p>

  <p>tgz_path = os.path.join(housing_path, “housing.tgz”)</p>

  <p>urllib.request.urlretrieve(housing_url, tgz_path)</p>

  <p>housing_tgz = tarfile.open(tgz_path)</p>

  <p>housing_tgz.extractall(path=housing_path)</p>

  <p>housing_tgz.close()</p>
</blockquote>

<p>Refer to below Colab Doc for further details</p>

<p><a href="https://colab.research.google.com/drive/1AFVgb6uXNfx0KxQmClv_HYspQ899B4c7?usp=sharing">https://colab.research.google.com/drive/1AFVgb6uXNfx0KxQmClv_HYspQ899B4c7?usp=sharing</a></p>

  </div><a class="u-url" href="/blog/2020/09/21/Notes_ML.html" hidden></a>
</article>