<article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Machine Learning Notes</h1><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-09-21T00:00:00-05:00" itemprop="datePublished">
        Sep 21, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <p>Deep Learning (Neural Networks) are much better to deal with most problems which all these algorithms can do.</p>

<p>Libraries – sklearn (scikit), IPython</p>

<p>Pandas and Numpy work well with each other.</p>

<p>Different Machine Learning Algorithms -</p>

<p><a href="https://scikit-learn.org/stable/supervised_learning.html">https://scikit-learn.org/stable/supervised_learning.html</a></p>

<p><a href="https://towardsdatascience.com/do-you-know-how-to-choose-the-right-machine-learning-algorithm-among-7-different-types-295d0b0c7f60">https://towardsdatascience.com/do-you-know-how-to-choose-the-right-machine-learning-algorithm-among-7-different-types-295d0b0c7f60</a></p>

<p>Prediction of Auction price for Bulldozers using Random Forests is the exercise.</p>

<p>Curse of Dimensionality and No Free Lunch theorem do not generally apply in real world.</p>

<ul>
  <li><a href="https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-1-84a1dc2b5236"><span class="underline">https://medium.com/@hiromi_suenaga/machine-learning-1-lesson-1-84a1dc2b5236</span></a></li>
</ul>

<p>RandomForestRegressor — regressor is a method for predicting continuous variables (i.e. regression)</p>

<p>RandomForestClassifier — classifier is a method for predicting categorical variables (i.e. classification)</p>

<p>For Notebooks – There is a bit of work which needs to be done before it is usable.</p>

<p>!pip install fastai==0.7.0</p>

<p>!pip3 install torch torchvision</p>

<p>!pip install ”torchtext==0.3.1”</p>

<p>!pip3 install spacy </p>

<p>!python -m spacy download en</p>

<p>from fastai.imports import *</p>

<p>from fastai.structured import *</p>

<p>from torch import * </p>

<p>from pandas_summary import DataFrameSummary</p>

<p>from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier</p>

<p>from IPython.display import display</p>

<p>from sklearn import metrics</p>

<p>Data will also have to be uploaded and will vanish once the Colab is disconnected.</p>

<p>For Lesson 1 – train.csv was uploaded after creating necessary folders on the colab machine.</p>

<p>Alternate solution for data is to use google drive and using that path in the program or downloading from URL (Kaggle or Google Drive). Use whichever works and is the fastest/easiest.</p>

<p><span class="underline">Random Forest Exercise Summary</span></p>

<p>Refer the Jupyter notebook for details - <a href="https://colab.research.google.com/drive/1ARrxUcm8cJdQ0J7sONa5FfQuan9nZSDH#scrollTo=6jeziZfhnA2x">https://colab.research.google.com/drive/1ARrxUcm8cJdQ0J7sONa5FfQuan9nZSDH#scrollTo=6jeziZfhnA2x</a></p>

<ul>
  <li>
    <p>Take an input csv. (CSV can be populated by any means with whatever relevant data is needed for your requirement)</p>
  </li>
  <li>
    <p>The goal is to predict a measure (in this case Auction Price)</p>
  </li>
  <li>
    <p>Look at the data to understand what it has type of columns (String, number, date…), NULL values, blank values etc.</p>
  </li>
  <li>
    <p>Read the csv data into a Pandas Dataframe. While reading there are options to specify if there are any date columns. Specify that and Pandas will read those as Dates rather than strings.</p>
  </li>
  <li>
    <p>Choose a Metric to evaluate the prediction vs actual.</p>
  </li>
</ul>

<blockquote>
  <p>It’s important to note what metric is being used for a project. Generally, selecting the metric(s) is an important part of the project setup. However, in this case Kaggle tells us what metric to use: RMSLE (root mean squared log error) to compare between the actual and predicted auction prices. Therefore, we take the log of the prices and then RMSE on top of this will give RMSLE.</p>
</blockquote>

<ul>
  <li>
    <p>The data contains continuous and categorical values.</p>
  </li>
  <li>
    <p>Any Date columns needs to be converted to Categoricals. If it is continuous (like how it is in the file i.e. just a date column), then we cannot capture trend and will not be useful for prediction. Below function does that and should be defined in your program and used. It is also present in fastai’s old library. But it converts to String Categoricals.</p>
  </li>
  <li>
    <p>Since the above functions converts the date into String Categoricals, we still need to convert it into Panda categoricals. Panda categoricals are like key value pair (0 value1 , 1 value2 and so on) for each of the values. This is needed for efficiency of the Random Forest. Below function is used for that purpose.</p>
  </li>
  <li>
    <p>Both these functions change the dataframe in-place. The function will need to be changed if it has to write to a different dataframe.</p>
  </li>
  <li>
    <p>Dataframe now has Category Objects in it for all non-numerical columns (each non-numerical column we saw in csv is a category object now). There are functions which can be run on Category objects in Python. Cat is one such function and it further has child functions.</p>
  </li>
  <li>
    <p>We now check for blank or missing values for all category objects. Below can give the percentage of such values in each of them. We will deal with them in a while.</p>
  </li>
</ul>

<p>display (df_raw.isnull().sum().sort_index()/len(df_raw))</p>

<ul>
  <li>
    <p>We can save the dataframe at such a point in a feather format. Saves to disc in the same format as it was in RAM.</p>
  </li>
  <li>
    <p>We can load it back from disc to a dataframe again later.</p>
  </li>
  <li>
    <p>Then we process the dataframe (proc_df) to fix missing values and more importantly makes a copy of dataframe, drops the dependent value (in this case Auction Price object) in this copy dataframe and converts categorical data into their respective codes It also adds 1 to codes to convert Null categories which will have code as -1 to 0 and this also changes the other codes to 1,2,3 and so on. Below is the function which can help with that. This function further uses other child functions mentioned below.</p>
  </li>
</ul>

<!-- end list -->

<ul>
  <li>The original dataframe is used to get the dependent value into a “y” variable.</li>
</ul>

<p><strong>The above output is in a format that can be passed into Random Forest Regressor.</strong></p>

<p>In statistics, the coefficient of determination, denoted R2 or r2 and pronounced “R squared”, is the proportion of the variance in the dependent variable that is predictable from the independent variable(s). <a href="https://en.wikipedia.org/wiki/Coefficient_of_determination">https://en.wikipedia.org/wiki/Coefficient_of_determination</a></p>

<p>m = RandomForestRegressor(n_jobs=-1)</p>

<p>m.fit(df, y)</p>

<p>m.score(df,y)</p>

<p>However, this could be an overfit since we have used all the data from train.csv</p>

<p>We need to verify this using a validation set. There are various hyperparameters that need to be set and various methods to be employed to get balances Random forest which has a balance between variance (highly overfit for Training data) and bias (highly biased even with Training data)</p>

<p>Good read - <a href="https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76">https://towardsdatascience.com/an-implementation-and-explanation-of-the-random-forest-in-python-77bf308a9b76</a></p>

<p>Different options for Random Forest Regressor.</p>

<p><a href="https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html">https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html</a></p>

  </div><a class="u-url" href="/blog/2020/09/21/Machine-Learning-Notes.html" hidden></a>
</article>